{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(10000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 10 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 1: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/home/sag/src_George/workspace/virtualenv/lib/python3.4/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "/home/sag/src_George/workspace/virtualenv/lib/python3.4/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/sag/src_George/workspace/virtualenv/lib/python3.4/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 10\n",
    "\n",
    "gpu_id='gpu1'\n",
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"device=\"+gpu_id +\",lib.cnmem=1\"\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers.advanced_activations import SReLU\n",
    "from keras import callbacks as ckbs\n",
    "import random\n",
    "import time\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from keras.models import model_from_json\n",
    "import pickle as pkl\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import *\n",
    "from keras.layers.wrappers import *\n",
    "from keras.optimizers import *\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import LSTM\n",
    "#from docutils.languages.af import labels\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.grid_search import GridSearchCV, ParameterGrid\n",
    "\n",
    "from sklearn.externals.joblib import load, dump\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = gzip.open('NerW2v.pkl', 'rb')\n",
    "data = pkl.load(f, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f = gzip.open('../data/embeddings_dial_ud_wiki.pkl.gz', 'rb')\n",
    "embeddings = pkl.load(f)\n",
    "f.close()\n",
    "\n",
    "label2Idx = embeddings['label2Idx']\n",
    "label_ud2Idx = embeddings['label_ud2Idx']\n",
    "wordEmbeddings = np.array(embeddings['wordEmbeddings'])\n",
    "caseEmbeddings = np.array(embeddings['caseEmbeddings'])\n",
    "\n",
    "#Inverse label mapping\n",
    "idx2Label = {v: k for k, v in label2Idx.items()}\n",
    "idx_ud2Label = {v: k for k, v in label_ud2Idx.items()}\n",
    "\n",
    "f = gzip.open('../data/data_dial_ud_wiki.pkl.gz', 'rb')\n",
    "    \n",
    "test_data_dial = pkl.load(f)\n",
    "train_data_dial = pkl.load(f)\n",
    "test_data_ud = pkl.load(f)\n",
    "train_data_ud = pkl.load(f)\n",
    "test_data_wiki = pkl.load(f)\n",
    "train_data_wiki = pkl.load(f)\n",
    "\n",
    "\n",
    "\n",
    "#test_data_dial = pkl.load(f)\n",
    "#train_data_dial = pkl.load(f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_out = len(label_ud2Idx)\n",
    "tokens = Sequential()\n",
    "tokens.add(Embedding(input_dim=wordEmbeddings.shape[0], output_dim=wordEmbeddings.shape[1],  weights=[wordEmbeddings], trainable=True))\n",
    "\n",
    "casing = Sequential()\n",
    "casing.add(Embedding(output_dim=caseEmbeddings.shape[1], input_dim=caseEmbeddings.shape[0], weights=[caseEmbeddings], trainable=True)) \n",
    "  \n",
    "model = Sequential();\n",
    "model.add(Merge([tokens, casing], mode='concat'))  \n",
    "model.add(Bidirectional(LSTM(10, return_sequences=True, dropout_W=0.25))) \n",
    "model.add(Bidirectional(LSTM(10, return_sequences=True, dropout_W=0.35))) \n",
    "model.add(TimeDistributed(Dense(n_out, activation='softmax')))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-7, momentum=0.0, nesterov=False, clipvalue=3) \n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tokens, casing, label = train_data[0]\n",
    "#labels = [x[0] for x in label]\n",
    "#labels = np.expand_dims([labels], -1)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(dataset, startIdx, endIdx): \n",
    "    endIdx = min(len(dataset), endIdx)\n",
    "    \n",
    "    for idx in range(startIdx, endIdx):\n",
    "        tokens, casing, label = dataset[idx] \n",
    "        #tokens, casing, label, char = dataset[idx]        \n",
    "        labels = [x[0] for x in label]\n",
    "        labels = np.expand_dims([labels], -1)     \n",
    "        yield labels, np.asarray([tokens]), np.asarray([casing])#, np.asarray([char])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def tag_dataset(dataset):\n",
    "    correctLabels = []\n",
    "    predLabels = []\n",
    "    #for tokens, casing, label, char in dataset:\n",
    "    for tokens, casing, label in dataset:    \n",
    "        tokens = np.asarray([tokens])     \n",
    "        casing = np.asarray([casing])\n",
    "        #char = np.asarray([char])\n",
    "        #pred = model.predict_classes([tokens, casing, char], verbose=False)[0]\n",
    "        pred = model.predict_classes([tokens, casing], verbose=False)[0] \n",
    "        labels = [x[0] for x in label]\n",
    "        correctLabels.append(labels)\n",
    "        predLabels.append(pred)\n",
    "        \n",
    "        \n",
    "        \n",
    "    return predLabels, correctLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx2Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def dialog_report(allINeed):\n",
    "\n",
    "    tags = {2:\"per\",0:\"loc\",1:\"org\"}\n",
    "    for fileName in list(set(allINeed[\"FileName\"])):\n",
    "        allObjects = []\n",
    "        currentObject = []\n",
    "        for cl in tags.keys():\n",
    "            for i,row in allINeed.loc[allINeed[\"FileName\"]==fileName].iterrows():\n",
    "                if row[\"mark\"]==cl:\n",
    "                    if len(currentObject)>0:\n",
    "                        lengthOfObj = int(row['posStartInText']) - int(currentObject[1]) + int(row['len'])\n",
    "                        currentObject[2] = lengthOfObj\n",
    "                    else:\n",
    "                        currentObject.append(tags[cl])\n",
    "                        currentObject.append(row['posStartInText'])\n",
    "                        currentObject.append(row['len'])\n",
    "                else:\n",
    "                    if len(currentObject)>0:\n",
    "                        currentObject[1]=str(int(currentObject[1]))\n",
    "                        currentObject[2]=str(int(currentObject[2]))\n",
    "                        allObjects.append(currentObject)\n",
    "                        currentObject = []\n",
    "            if len(currentObject)>0:\n",
    "                currentObject[1]=str(int(currentObject[1]))\n",
    "                currentObject[2]=str(int(currentObject[2]))\n",
    "                allObjects.append(currentObject)\n",
    "                currentObject = []\n",
    "        allObjects = [\" \".join(obj)+\"\\n\" for obj in allObjects]\n",
    "        WriteLinesTo(allObjects,\"./forTests/\"+fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def WriteLinesTo(allObjects, fileName):\n",
    "    f = open(fileName, \"w+\")\n",
    "    #print(len(allObjects))\n",
    "    f.writelines(allObjects)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "list(idx2Label.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label2Idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(train_data, test_data, model):\n",
    "    import time\n",
    "    number_of_epochs = 30\n",
    "    stepsize = 24000\n",
    "    print(\"%d epochs\" % number_of_epochs)\n",
    "\n",
    "    print(\"%d train sentences\" % len(train_data))\n",
    "    print(\"%d test sentences\" % len(test_data))\n",
    "    macc = 0.0\n",
    "    for epoch in range(number_of_epochs):    \n",
    "        print(\"--------- Epoch %d -----------\" % epoch)\n",
    "        random.shuffle(train_data)\n",
    "        for startIdx in range(0, len(train_data), stepsize):\n",
    "            start_time = time.time()    \n",
    "            for batch in iterate_minibatches(train_data, startIdx, startIdx+stepsize):\n",
    "                #labels, tokens, casing, char = batch\n",
    "                labels, tokens, casing = batch\n",
    "                #print(tokens.shape)\n",
    "                #print(labels.shape)\n",
    "                model.train_on_batch([tokens, casing], labels)\n",
    "                #model.train_on_batch([tokens, casing, char], labels)   \n",
    "            print(\"%.2f sec for training\" % (time.time() - start_time))\n",
    "            predLabels, correctLabels = tag_dataset(test_data)\n",
    "            xx = []\n",
    "            for x in correctLabels:\n",
    "                for y in x:\n",
    "                    xx.append(y)\n",
    "            yy = []\n",
    "            for x in predLabels:\n",
    "                for y in x:\n",
    "                    yy.append(y)\n",
    "            acc = accuracy_score(xx, yy)\n",
    "            print(acc)\n",
    "            if acc > macc:\n",
    "                macc = acc\n",
    "                model.save('model_dial_afterwikiud_all_words_embed.h5')\n",
    "                print(\"save_model\")\n",
    "            print(classification_report(xx, yy, target_names=list(idx_ud2Label.values())))#['LOC','O', 'ORG','PER']))\n",
    "    return macc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "macc = train(train_data_ud, test_data_ud, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = load_model('model_wiki_afterud_all_words_embed.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "macc = train(train_data_dial, test_data_dial, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_result(dataset, model):\n",
    "    correctLabels = []\n",
    "    predLabels = []\n",
    "    #for tokens, casing, label, char in dataset:\n",
    "    for tokens, casing, label in dataset:    \n",
    "        tokens = np.asarray([tokens])     \n",
    "        casing = np.asarray([casing])\n",
    "        #char = np.asarray([char])\n",
    "        #pred = model.predict_classes([tokens, casing, char], verbose=False)[0]\n",
    "        pred = model.predict_classes([tokens, casing], verbose=False)[0] \n",
    "        labels = [x[0] for x in label]\n",
    "        correctLabels.append(labels)\n",
    "        predLabels.append(pred)\n",
    "    yy = []\n",
    "    for x in predLabels:\n",
    "        for y in x:\n",
    "            yy.append(y)\n",
    "    xx = []\n",
    "    for x in correctLabels:\n",
    "        for y in x:\n",
    "            xx.append(y)\n",
    "    acc = accuracy_score(xx, yy)\n",
    "    print(acc)\n",
    "    print(classification_report(xx, yy, target_names=list(idx2Label.values())))#['LOC','O', 'ORG','PER']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('model_dial_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_result(test_data_dial, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pop_layer(model):\n",
    "    if not model.outputs:\n",
    "        raise Exception('Sequential model cannot be popped: model is empty.')\n",
    "\n",
    "    model.layers.pop()\n",
    "    if not model.layers:\n",
    "        model.outputs = []\n",
    "        model.inbound_nodes = []\n",
    "        model.outbound_nodes = []\n",
    "    else:\n",
    "        model.layers[-1].outbound_nodes = []\n",
    "        model.outputs = [model.layers[-1].output]\n",
    "    model.built = False\n",
    "pop_layer(model)\n",
    "model.add(TimeDistributed(Dense(len(label2Idx)-1, activation='softmax')))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-7, momentum=0.0, nesterov=False, clipvalue=3) \n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train(train_data_dial, test_data_dial, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_dataset(dataset):\n",
    "    correctLabels = []\n",
    "    predLabels = []\n",
    "    for tokens, casing, labels in dataset:    \n",
    "        tokens = np.asarray([tokens])     \n",
    "        casing = np.asarray([casing])\n",
    "        pred = model.predict_classes([tokens, casing], verbose=False)[0] \n",
    "        #labels = [x[0] for x in label]\n",
    "        correctLabels.append(labels)\n",
    "        predLabels.append(pred)\n",
    "    yy = []\n",
    "    for x in predLabels:\n",
    "        for y in x:\n",
    "            yy.append(y)\n",
    "    xx = []\n",
    "    for x in correctLabels:\n",
    "        for y in x:\n",
    "            xx.append(y)\n",
    "    for x in range(0, len(xx)):\n",
    "        xx[x][0] = yy[x]\n",
    "    return xx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_test_t = pd.read_csv('../data/Dialog_test/NER_testset.targets.csv', sep=';')\n",
    "df_test = pd.read_csv('../data/Dialog_test/NER_testset.features.csv', sep=';')\n",
    "df_test = df_test[['pos','link', 'len', 'lemma', 'isupper', 'istitle', 'islower', 'isdigit', 'isalpha', 'isalnum', 'isLastWord', 'isFirstWord', 'grm', 'posStartInText']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#dialog -------------------- dialog\n",
    "y_t = get_dataset(test_data_dial)\n",
    "allINeed = pd.DataFrame(y_t, columns=[\"mark\",  \"posStartInText\", \"FileName\", \"len\"])\n",
    "dialog_report(allINeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

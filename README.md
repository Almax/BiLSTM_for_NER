# BiLSTM_for_NER

This project present experiments with neural network model based on using of bilsm layer in combination with semantic words distribution features, case information, symbolwise neural network words of sentence encoding. For  semantic features we used w2v for lemms and forms. Model training was implemented on different combinations of datasets, including auto marked articles from russian wiki and part of speech corpus. Research involve applying  model to different languages.
We were achived for russian language F1=0.96
